---
layout: post 
category: papers 
---
---
​		适合磁盘的索引通常有两种，一种是就地更新（B+Tree），一种是非就地更新（LSM）。就地更新的索引结构拥有最好的读性能（随机读和顺序读），而随机写性能很差，无法满足显示工业负载要求。（B+树适合读多写少的任务）而非就地更新数据结构LSM充分发挥顺序写入的高性能特性，成为写入密集数据系统的基础。

​		<font color="red">基本思想</font>：既然硬盘的特性决定了他随机写入的性能很差，那么就设法将随机写操作转化为顺序写。将所有键-值对一个接一个放到硬盘中(<font color="red">日志紧追加</font>)，因为每一个键-值对之间并没有关联，他们在硬盘中存放的顺序也没有关联，所以是“随机”的，但是这样在写入键-值对的时候对硬盘来说又是连续的。不需要涉及随机写入。如果需要修改前面已经写入的键值对，并不去随机读写，而是把修改后的键-值对按照日志紧追加的方式添加到日志尾部。这样就会导致一个key被写入多次的情况，会在磁盘中留下无效数据。这种情况会导致两种问题：浪费磁盘空间、导致读产生问题（必须for循环整个键-值对序列日志，才能找到最新的有效数据）。

​		上面这种简单的思路是为了满足写入密集型数据库的要求，但是他的读取性能会非常差。<font color="red">实际需求：支持很高的写吞吐量、不太高的读吞吐量、很低的读延迟</font>

​		为了解决修改键–值对时插入新日志导致旧日志失效，浪费存储空间且拉低读取效率的问题，一个思路是垃圾回收（GC），删除无效的键-值对。垃圾回收遇到的问题：系统无法确定当前的键是否是已经存在的键，解决方案：<font color="red">将日志分段</font>。（日志分段的另一个好处：文件系统对大文件缓存比较难以处理，将大文件分成小段可以方便操作）将日志文件分段之后，只有一个分段是活跃的文件（可以向其中写入），当写入的日志量达到阈值之后，就将它设置为一个不可写的文件，然后创建一个新的可以写入的文件（<font color="red">滚动地写入</font>）。那些不可变的文件就可以提交给垃圾回收进程进行清理。gc只要遍历这些文件，维护一个C++ map，可能还需要维护每条日志的写入顺序，然后按照顺序将所需的键-值对重新写入即可。通过这样的垃圾回收操作，可以保证垃圾回收后的日志和回收前的日志是等效的。

​		leveldb需要满足的操作：get、set、range（顺序读取，比如想要顺序获取当天24小时内的日志，思路是结合上面对日志的分段，使用归并排序，只需要将有重叠日志的文件进行归并，没有重叠日志的文件可以不归并）

​		那么如何优化读取性能呢？

​		思路1：<font color="red">利用内存</font>，将最近最新写入的kv存储在内存数据结构中（红黑树、**跳表**等）。leveldb使用的是跳表。首先在内存中用数据结构存储日志，当内存中的数据结构足够大的时候，将它整体dump到硬盘中形成一个日志文件。（不需要每次写入都调用硬盘，积累一批再调用硬盘）<font color="red">上面的方法带来的问题</font>：写入是连续的，而将内存中的数据结构dump到硬盘的过程可能没有新数据写入快，那么dump的过程是不是永远无法停止？需要<font color="red">在内存中维护两个跳表</font>：活跃跳表和不变跳表，活跃跳表接受新的写入请求，写入数据量达到阈值就将他转化为不可变跳表，然后这个不可变跳表会被dump进程dump到硬盘中。<font color="red">另一个问题</font>：数据写入到内存时成功了，但是还没有持久化。如果此时发生错误（机器故障），而内存又是易失存储，如何保证可靠性？使用<font color="red">预写日志</font>,使用日志紧追加并且没有其他任何优化的方式（预写日志没有必要保存其读取性能）暂存日志，如果发生系统故障，可以用预写日志恢复内存中丢失的数据。预写日志仅仅保留那些没有被写入到磁盘的数据。<font color="red">还有一个问题</font>：内存大小有限，不能缓存所有数据，加入要读取的键是很老的键，还是需要遍历所有的日志文件。<font color="red">**将日志段文件分层分级**</font>:

### leveldb最核心的思想

这也是leveldb名称中level的由来。日志段归并的时候有最大key和最小key，从内存中直接dump下来的文件，由于内存中的跳表是有序的，所以dump到硬盘中也是有序的（文件从出生开始就是有序的），但是由于写入是随机的，文件之间可能有重叠，所以需要归并，定义从来没有被归并的文件是第零层归并的文件，归并一次之后的文件是第一次归并的文件，归并之后可以保证**所有的第一次归并的文件一定不会有重叠的情况出现**因为这些文件在归并过程中已经把所有重复文件处理掉了。随着归并的文件数量增加，文件会越来越大。再对文件进行第二层的归并。我们需要考虑到当第零层归并文件逐渐被归并到第一层的文件中时，还会有新的文件从内存中被dump到第零层归并文件。也就是潜在的日志条目交叉会不断发生，需要不断地进行归并。leveldb就要执行这样一个将日志文件一层一层不断归并的过程。按照归并的次数对文件进行分层。

​		分多层的好处是：除了第零层的日志文件之外，每一层的文件互相之间不会有重复覆盖的情况发生。当我们需要找到特定的key时，只需要根据key值的范围找到某一层中对应的文件，查找该文件中是否有这个key，如果这个文件中没找到，那么这一层的其他文件中也不会找到这个key。（每一层中只需要遍历一个文件，且层数是有限的，那么需要遍历的文件数也是有限的）。第零层比较特殊，因为他是直接从内存dump得到的，无法保证文件之间key的范围没有重叠，所以必须遍历第零层的所有文件。解决方案是限制第零层中文件的数目，一旦第零层中的文件数目大于规定的数目，就触发一次merge操作。通过以上方法，可以保证读取一个特定的key时，需要遍历的文件总是常数数量级的。

​		随着归并次数增多，每一层的日志文件大小会增加，每一级会比上一级大一个数量级的文件大小。一般C0文件定义为2M。高层文件难以被一次性加入到内存，因此需要一定的磁盘索引机制。我们对每个磁盘文件进行布局设计，分为元数据块、索引块、数据块三大块。元数据块中存储布隆过滤器（这种过滤器判定不存在的话就一定不存在，那么就可以忽略这个文件）快速判断这个文件中是否存在某个key，同时通过对排序索引（通常缓存在内存中）二分查找定位key所在磁盘的位置。进而加速读取的速度，我们叫这种数据文件为SSTABLE（字符串排序表）。

